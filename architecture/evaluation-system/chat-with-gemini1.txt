这是一份为您整合的 **《Agent Evaluation Platform (AEP) 核心架构与产品设计全案》**。它凝结了我们关于 Benchmark 演进、Persona 与 Exedra 双框架逻辑、以及“对抗产生数据、数据驱动评估”核心理念的深度对话成果。

---

# 📜 Agent Evaluation Platform (AEP) 深度设计全案

## 1. 行业洞察：从静态 Bench 到动态 Arena

在 Agent 评测领域，**Benchmark** 与 **Bench** 的内涵已发生根本性变革：

* **传统阶段：** Bench 是静态的“考卷”（JSON/CSV），Agent 只是被动地回答行数据。
* **AEP 阶段：** Bench 是一个**“模拟考场 (Arena)”**。对于复杂的 Persona (演绎型) 和 Exedra (共创型) Agent，我们认为**只有通过模拟对抗（Simulation）试出的表现，才是 Agent 的真实能力。**

---

## 2. 核心架构：双框架体系

平台服务于企业内部团队，通过底层两类框架覆盖所有垂直业务领域：

* **Persona Framework (演绎系)：** 侧重专家分身的忠诚度与一致性。
* *典型产品：* AI 老师、AI 销售、AI 测评、AI 陪练等。
* *评估核心：* 控场力、人格魅力、专业知识、情绪情绪稳定性。


* **Exedra Framework (共创系)：** 侧重复杂任务的协同与达成。
* *典型产品：* 内容创作顾问、培训顾问、BP 顾问等。
* *评估核心：* 推进效率、共识达成率、工具调用精度、方案通过率。



---

## 3. 菜单架构设计 (二级结构)

为保持系统简洁，通过 **“一级导航 + 二级视图 + 页面内 Filter”** 实现复杂逻辑。

### 🏆 I. 效能榜单 (Performance Leaderboard)

* **核心逻辑：** 结果看板。展示 Agent 在数千场模拟对抗后的业务终态（Final Outcomes）。
* **交互设计：** 顶部切换 Persona/Exedra 标签，侧边通过行业（AI 销售、BP 顾问等）进行 Filter。
* **可视化：** * Persona 侧重**“人格雷达图”**（人设稳定性、话术吸引力等）。
* Exedra 侧重**“任务流向图”**（协同环节效率、最终成功率）。



### 🚀 II. 评测实验室 (Evaluation Jobs)

* **核心逻辑：** 任务引擎。管理 Agent 的“红蓝对抗”实验进程。
* **流程：** 开发者在此发起 Job，系统自动调度 **Candidate Agent** 与 **Simulator Agent** 进行博弈。
* **产出：** 对抗过程会产生海量的全量对话日志 (Logs) 和行为轨迹 (Trace)，作为评估的原始资料。

### 📚 III. 基准工坊 (Benchmark Studio)

* **核心逻辑：** 资产中心。在此配置“题库”与“考场环境”，而非简单的文件上传。
* **三位一体：**
1. **模拟器配置 (Simulators)：** 维护那个“刁难人的客户”或“厌学的学生”的 NPC 人设与逻辑。
2. **剧本维护 (Scenarios)：** 设计对抗发生的故事情节（如：双 11 期间的退款纠纷场景）。
3. **裁判定义 (Judges)：** 配置评估 Agent 行为数据的 Prompts（如：检查 Agent 是否在对话中提及了核心利益点）。



### 🔍 行为透视 (Trace & Analysis)

* **核心逻辑：** 复盘工具。将抽象的分数还原为可视化的对抗回放。
* **设计：** 采用**双屏对比视图**。左侧展示 Candidate Agent，右侧展示模拟器（Simulator）的反馈及隐藏状态。
* **功能：** 提取“决胜帧”，分析哪一句话导致了对抗的失败或协同的崩盘。

### 🛠 准入审核 (Gatekeeper)

* **核心逻辑：** 质量卡点。基于对抗数据的统计结果，决定 Agent 能否部署到生产环境。
* **红线：** 强制性的风险合规测试，只有在极限模拟环境下不触发敏感词、胜率达标的 Agent 才能过审。

---

## 4. 关键技术逻辑：对抗 vs 评估

我们的设计区别于传统平台，核心流程闭环如下：

1. **场景触发：** 在 `基准工坊` 定义一个 AI 老师对抗场景（设置：模拟学员会尝试调戏老师）。
2. **动态对抗：** 在 `评测实验室` 运行。Candidate Agent 与模拟学员进行 10 轮对话。
3. **数据沉淀：** 无论对抗结果如何，所有的 Action 和 Response 被记录为行为轨迹数据。
4. **智能抽提：** 系统自动将数据抛给“裁判模型”，根据 `基准工坊` 里的评分项（如：知识点讲解完整度）进行多维打分。
5. **榜单更新：** 最终分数沉淀到 `效能榜单`，供业务方选优。

---

## 5. 后续迭代建议

* **数据回流 (SFT Support)：** 将 `行为透视` 中那些“反败为胜”的极高分对抗轨迹，一键导出为 SFT 训练集，用于模型进化。
* **协同模拟 (Multi-Agent)：** 针对 Exedra 框架，支持引入多个 Simulator 模拟更复杂的“多人办公协同”环境。

---

**这份文档已准备好作为您的项目白皮书。下一步，我们要细化哪一个页面的具体 UI 布局，或者是某个“场景模拟器”的配置逻辑？**