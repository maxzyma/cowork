     1â†’---
     2â†’title: Core Concepts
     3â†’---
     4â†’
     5â†’# Long-term Memory in LLM Applications
     6â†’
     7â†’Long-term memory allows agents to remember important information across conversations. LangMem provides ways to extract meaningful details from chats, store them, and use them to improve future interactions. At its core, each memory operation in LangMem follows the same pattern:
     8â†’
     9â†’1. Accept conversation(s) and current memory state
    10â†’2. Prompt an LLM to determine how to expand or consolidate the memory state
    11â†’3. Respond with the updated memory state
    12â†’
    13â†’The best memory systems are often application-specific. In designing yours, the following questions can serve as a useful guide:
    14â†’
    15â†’1. **What** [type of content](#memory-types) should your agent learn: facts/knowledge? summary of past events? Rules and style?
    16â†’2. **When** should the [memories be formed](#writing-memories) (and **who** should form the memories)
    17â†’3. **Where** should memories [be stored](#storage-system)? (in the prompt? Semantic store?). This largely determines how they will be recalled.
    18â†’
    19â†’## Types of Memory {#memory-types}
    20â†’
    21â†’Memory in LLM applications can reflect some of the structure of human memory, with each type serving a distinct purpose in building adaptive, context-aware systems:
    22â†’
    23â†’
    24â†’| Memory Type | Purpose | Agent Example | Human Example | Typical Storage Pattern |
    25â†’|-------------|---------|---------------|---------------|-----------------------|
    26â†’| Semantic | Facts & Knowledge | User preferences; knowledge triplets | Knowing Python is a programming language | Profile or Collection |
    27â†’| Episodic | Past Experiences | Few-shot examples; Summaries of past conversations | Remembering your first day at work | Collection |
    28â†’| Procedural | System Behavior | Core personality and response patterns | Knowing how to ride a bicycle | Prompt rules or Collection |
    29â†’
    30â†’### Semantic Memory: Facts and Knowledge
    31â†’
    32â†’[Semantic memory](https://en.wikipedia.org/wiki/Semantic_memory) stores the essential facts and other information that ground an agent's responses. Two common representations of semantic memory are collections (to record an unbounded amount of knowledge to be searched at runtime) and profiles (to record task-specific information that follows a strict schema that is easily looked up by user or agent). 
    33â†’
    34â†’#### Collection
    35â†’
    36â†’Collections are what most people think of when they imagine agent long-term memory. In this type, memories are stored as individual documents or records. For each new conversation, the memory system can decide to insert new memories to the store. 
    37â†’
    38â†’Using a collection-type memory adds some complexity to the process of updating your memory state. The system must reconcile new information with previous beliefs, either _deleting_/_invalidating_ or _updating_/_consolidating_ existing memories. If the system over-extracts, this could lead to reduced precision of memories when your agent needs to search the store. If it under-extracts, this could lead to low recall. LangMem uses a memory enrichment process that strives to balance memory creation and consolidation, while letting you, the developer, customize the instructions to further shift the strength of each.
    39â†’
    40â†’Finally, memory relevance is more than just semantic similarity. Recall should combine similarity with "importance" of the memory, as well as the memory's "strength", which is a function of how recently/frequently it was used.
    41â†’
    42â†’![Collection update process](img/update-list.png)
    43â†’
    44â†’??? example "Extracting semantic memories as collections"
    45â†’
    46â†’    ??? note "Setup"
    47â†’
    48â†’        ```python
    49â†’        from langmem import create_memory_manager
    50â†’        
    51â†’        # highlight-next-line
    52â†’        manager = create_memory_manager(
    53â†’            "anthropic:claude-3-5-sonnet-latest",
    54â†’            instructions="Extract all noteworthy facts, events, and relationships. Indicate their importance.",
    55â†’            # highlight-next-line
    56â†’            enable_inserts=True,
    57â†’        )
    58â†’
    59â†’        # Process a conversation to extract semantic memories
    60â†’        conversation = [
    61â†’            {"role": "user", "content": "I work at Acme Corp in the ML team"},
    62â†’            {"role": "assistant", "content": "I'll remember that. What kind of ML work do you do?"},
    63â†’            {"role": "user", "content": "Mostly NLP and large language models"}
    64â†’        ]
    65â†’        ```
    66â†’
    67â†’    ```python
    68â†’    memories = manager.invoke({"messages": conversation})
    69â†’    # Example memories:
    70â†’    # [
    71â†’    #     ExtractedMemory(
    72â†’    #         id="27e96a9d-8e53-4031-865e-5ec50c1f7ad5",
    73â†’    #         content=Memory(
    74â†’    #             content="[IMPORTANT] User prefers to be called Lex (short for Alex) and appreciates"
    75â†’    #             " casual, witty communication style with relevant emojis."
    76â†’    #         ),
    77â†’    #     ),
    78â†’    #     ExtractedMemory(
    79â†’    #         id="e2f6b646-cdf1-4be1-bb40-0fd91d25d00f",
    80â†’    #         content=Memory(
    81â†’    #             content="[BACKGROUND] Lex is proficient in Python programming and specializes in developing"
    82â†’    #             " AI systems with a focus on making them sound more natural and less corporate."
    83â†’    #         ),
    84â†’    #     ),
    85â†’    #     ExtractedMemory(
    86â†’    #         id="c1e03ebb-a393-4e8d-8eb7-b928d8bed510",
    87â†’    #         content=Memory(
    88â†’    #             content="[HOBBY] Lex is a competitive speedcuber (someone who solves Rubik's cubes competitively),"
    89â†’    #             " showing an interest in both technical and recreational puzzle-solving."
    90â†’    #         ),
    91â†’    #     ),
    92â†’    #     ExtractedMemory(
    93â†’    #         id="ee7fc6e4-0118-425f-8704-6b3145881ff7",
    94â†’    #         content=Memory(
    95â†’    #             content="[PERSONALITY] Based on communication style and interests, Lex appears to value authenticity,"
    96â†’    #             " creativity, and technical excellence while maintaining a fun, approachable demeanor."
    97â†’    #         ),
    98â†’    #     ),
    99â†’    # ]
   100â†’
   101â†’    ```
   102â†’
   103â†’#### Profiles
   104â†’
   105â†’**Profiles** on the other hand are well-scoped for a particular task. Profiles are a single document that represents the current state, like a user's main goals with using an app, their preferred name and response style, etc. When new information arrives, it updates the existing document rather than creating a new one. This approach is ideal when you only care about the latest state and want to avoid remembering extraneous information.
   106â†’
   107â†’![Profile update process](img/update-profile.png)
   108â†’
   109â†’??? example "Managing user preferences with profiles"
   110â†’
   111â†’    ??? note "Setup"
   112â†’
   113â†’        ```python
   114â†’        from langmem import create_memory_manager
   115â†’        from pydantic import BaseModel
   116â†’
   117â†’
   118â†’        class UserProfile(BaseModel):
   119â†’            """Save the user's preferences."""
   120â†’            name: str
   121â†’            preferred_name: str
   122â†’            response_style_preference: str
   123â†’            special_skills: list[str]
   124â†’            other_preferences: list[str]
   125â†’
   126â†’
   127â†’        manager = create_memory_manager(
   128â†’            "anthropic:claude-3-5-sonnet-latest",
   129â†’            schemas=[UserProfile],
   130â†’            instructions="Extract user preferences and settings",
   131â†’            enable_inserts=False,
   132â†’        )
   133â†’
   134â†’        # Extract user preferences from a conversation
   135â†’        conversation = [
   136â†’            {"role": "user", "content": "Hi! I'm Alex but please call me Lex. I'm a wizard at Python and love making AI systems that don't sound like boring corporate robots ðŸ¤–"},
   137â†’            {"role": "assistant", "content": "Nice to meet you, Lex! Love the anti-corporate-robot stance. How would you like me to communicate with you?"},
   138â†’            {"role": "user", "content": "Keep it casual and witty - and maybe throw in some relevant emojis when it feels right âœ¨ Also, besides AI, I do competitive speedcubing!"},
   139â†’        ]
   140â†’        ```
   141â†’
   142â†’    ```python
   143â†’    profile = manager.invoke({"messages": conversation})[0]
   144â†’    print(profile)
   145â†’    # Example profile:
   146â†’    # ExtractedMemory(
   147â†’    #     id="6f555d97-387e-4af6-a23f-a66b4e809b0e",
   148â†’    #     content=UserProfile(
   149â†’    #         name="Alex",
   150â†’    #         preferred_name="Lex",
   151â†’    #         response_style_preference="casual and witty with appropriate emojis",
   152â†’    #         special_skills=[
   153â†’    #             "Python programming",
   154â†’    #             "AI development",
   155â†’    #             "competitive speedcubing",
   156â†’    #         ],
   157â†’    #         other_preferences=[
   158â†’    #             "prefers informal communication",
   159â†’    #             "dislikes corporate-style interactions",
   160â†’    #         ],
   161â†’    #     ),
   162â†’    # )
   163â†’    ```
   164â†’
   165â†’Choose between profiles and collections based on how you'll use the data: profiles excel when you need quick access to current state and when you have data requirements about what type of information you can store. They are also easy to present to a user for manual editing. Collections are useful when you want to track knowledge across many interactions without loss of information, and when you want to recall certain information contextually rather than every time.
   166â†’
   167â†’### Episodic Memory: Past Experiences
   168â†’
   169â†’Episodic memory preserves successful interactions as learning examples that guide future behavior. Unlike semantic memory which stores facts, episodic memory captures the full context of an interactionâ€”the situation, the thought process that led to success, and why that approach worked. These memories help the agent learn from experience, adapting its responses based on what has worked before.
   170â†’
   171â†’??? example "Defining and extracting episodes"
   172â†’    
   173â†’    ??? note "Setup"
   174â†’
   175â†’        ```python
   176â†’        from pydantic import BaseModel, Field
   177â†’        from langmem import create_memory_manager
   178â†’
   179â†’        class Episode(BaseModel):
   180â†’            """An episode captures how to handle a specific situation, including the reasoning process
   181â†’            and what made it successful."""
   182â†’            
   183â†’            observation: str = Field(
   184â†’                ..., 
   185â†’                description="The situation and relevant context"
   186â†’            )
   187â†’            thoughts: str = Field(
   188â†’                ...,
   189â†’                description="Key considerations and reasoning process"
   190â†’            )
   191â†’            action: str = Field(
   192â†’                ...,
   193â†’                description="What was done in response"
   194â†’            )
   195â†’            result: str = Field(
   196â†’                ...,
   197â†’                description="What happened and why it worked"
   198â†’            )
   199â†’
   200â†’        # highlight-next-line
   201â†’        manager = create_memory_manager(
   202â†’            "anthropic:claude-3-5-sonnet-latest",
   203â†’            schemas=[Episode],
   204â†’            instructions="Extract examples of successful interactions. Include the context, thought process, and why the approach worked.",
   205â†’            enable_inserts=True,
   206â†’        )
   207â†’
   208â†’        # Example conversation
   209â†’        conversation = [
   210â†’            {"role": "user", "content": "What's a binary tree? I work with family trees if that helps"},
   211â†’            {"role": "assistant", "content": "A binary tree is like a family tree, but each parent has at most 2 children. Here's a simple example:\n   Bob\n  /  \\\nAmy  Carl\n\nJust like in family trees, we call Bob the 'parent' and Amy and Carl the 'children'."},
   212â†’            {"role": "user", "content": "Oh that makes sense! So in a binary search tree, would it be like organizing a family by age?"},
   213â†’        ]
   214â†’        ```
   215â†’
   216â†’    ```python
   217â†’    # Extract episode(s)
   218â†’    episodes = manager.invoke({"messages": conversation})
   219â†’    # Example episode:
   220â†’    # [
   221â†’    #     ExtractedMemory(
   222â†’    #         id="f9194af3-a63f-4d8a-98e9-16c66e649844",
   223â†’    #         content=Episode(
   224â†’    #             observation="User struggled debugging a recursive "
   225â†’    #                         "function for longest path in binary "
   226â†’    #                         "tree, unclear on logic.",
   227â†’    #             thoughts="Used explorer in treehouse village "
   228â†’    #                      "metaphor to explain recursion:\n"
   229â†’    #                      "- Houses = Nodes\n"
   230â†’    #                      "- Bridges = Edges\n"
   231â†’    #                      "- Explorer's path = Traversal",
   232â†’    #             action="Reframed problem using metaphor, "
   233â†’    #                    "outlined steps:\n"
   234â†’    #                    "1. Check left path\n"
   235â†’    #                    "2. Check right path\n"
   236â†’    #                    "3. Add 1 for current position\n"
   237â†’    #                    "Highlighted common bugs",
   238â†’    #             result="Metaphor helped user understand logic. "
   239â†’    #                    "Worked because it:\n"
   240â†’    #                    "1. Made concepts tangible\n"
   241â†’    #                    "2. Created mental model\n"
   242â†’    #                    "3. Showed key steps\n"
   243â†’    #                    "4. Pointed to likely bugs",
   244â†’    #         ),
   245â†’    #     )
   246â†’    # ]
   247â†’    ```
   248â†’
   249â†’
   250â†’### Procedural Memory: System Instructions
   251â†’
   252â†’Procedural memory encodes how an agent should behave and respond. It starts with system prompts that define core behavior, then evolves through feedback and experience. As the agent interacts with users, it refines these instructions, learning which approaches work best for different situations.
   253â†’
   254â†’![Instructions update process](img/update-instructions.png)
   255â†’
   256â†’??? example "Optimizing prompts based on feedback"
   257â†’
   258â†’    ??? note "Setup"
   259â†’
   260â†’        ```python
   261â†’        from langmem import create_prompt_optimizer
   262â†’
   263â†’        # highlight-next-line
   264â†’        optimizer = create_prompt_optimizer(
   265â†’            "anthropic:claude-3-5-sonnet-latest",
   266â†’            kind="metaprompt",
   267â†’            config={"max_reflection_steps": 3}
   268â†’        )
   269â†’        ```
   270â†’    ```python
   271â†’    prompt = "You are a helpful assistant."
   272â†’    trajectory = [
   273â†’        {"role": "user", "content": "Explain inheritance in Python"},
   274â†’        {"role": "assistant", "content": "Here's a detailed theoretical explanation..."},
   275â†’        {"role": "user", "content": "Show me a practical example instead"},
   276â†’    ]
   277â†’    optimized = optimizer.invoke({
   278â†’        "trajectories": [(trajectory, {"user_score": 0})], 
   279â†’        "prompt": prompt
   280â†’    })
   281â†’    print(optimized)
   282â†’    # You are a helpful assistant with expertise in explaining technical concepts clearly and practically. When explaining programming concepts:
   283â†’
   284â†’    # 1. Start with a brief, practical explanation supported by a concrete code example
   285â†’    # 2. If the user requests more theoretical details, provide them after the practical example
   286â†’    # 3. Always include working code examples for programming-related questions
   287â†’    # 4. Pay close attention to user preferences - if they ask for a specific approach (like practical examples or theory), adapt your response accordingly
   288â†’    # 5. Use simple, clear language and break down complex concepts into digestible parts
   289â†’
   290â†’    # When users ask follow-up questions or request a different approach, immediately adjust your explanation style to match their preferences. If they ask for practical examples, provide them. If they ask for theory, explain the concepts in depth.
   291â†’    ```
   292â†’
   293â†’
   294â†’
   295â†’## Writing memories {#writing-memories}
   296â†’
   297â†’Memories can form in two ways, each suited for different needs. Active formation happens during conversations, enabling immediate updates when critical context emerges. Background formation occurs between interactions, allowing deeper pattern analysis without impacting response time. This dual approach lets you balance responsiveness with thorough learning.
   298â†’
   299â†’| Formation Type | Latency Impact | Update Speed | Processing Load | Use Case |
   300â†’|----------------|----------------|--------------|-----------------|-----------|
   301â†’| Active | Higher | Immediate | During Response | Critical Context Updates |
   302â†’| Background | None | Delayed | Between/After Calls | Pattern Analysis, Summaries |
   303â†’
   304â†’![Hot path vs background memory processing](img/hot_path_vs_background.png)
   305â†’
   306â†’### Conscious Formation
   307â†’
   308â†’You may want your agent to save memories "in the hot path". This active memory formation happens during the conversation, enabling immediate updates when critical context emerges. This approach is easy to implement and lets the agent itself choose how to store and update its memory. However, it adds perceptible latency to user interactions, and it adds one more obstacle to the agent's ability to satisfy the user's needs.
   309â†’
   310â†’Check out the ["hot path" quickstart](../hot_path_quickstart.md) for an example of how to use this technique.
   311â†’
   312â†’### Subconscious Formation
   313â†’
   314â†’"Subconscious" memory formation refers to the technique of prompting an LLM to reflect on a conversation after it occurs (or after it has been inactive for some period), finding patterns and extracting insights without slowing down the immediate interaction or adding complexity to the agent's tool choice decisions. This approach is perfect for ensuring higher recall of extracted information.
   315â†’
   316â†’Check out the ["background" quickstart](../background_quickstart.md) for an example of how to use this technique.
   317â†’
   318â†’## Integration Patterns
   319â†’
   320â†’LangMem's memory utilities are organized in two layers of integration patterns:
   321â†’
   322â†’### 1. Core API {#functional-core}
   323â†’
   324â†’At its heart, LangMem provides functions that transform memory state without side effects. These primitives are the building blocks for memory operations:
   325â†’
   326â†’- [**Memory Managers**](../reference/memory.md#langmem.create_memory_manager): Extract new memories, update or remove outdated memories, and consolidate and generalize from existing memories based on new conversation information
   327â†’- [**Prompt Optimizers**](../reference/prompt_optimization.md#langmem.create_prompt_optimizer): Update prompt rules and core behavior based on conversation information (with optional feedback)
   328â†’
   329â†’These core functions do not depend on any particular database or storage system. You can use them in any application.
   330â†’
   331â†’### 2. Stateful Integration
   332â†’
   333â†’The next layer up depends on LangGraph's long-term memory store. These components use the core API above to transform memories that exist in the store and upsert/delete them as needed when new conversation information comes in:
   334â†’
   335â†’- [**Store Managers**](../reference/memory.md#langmem.create_memory_store_manager): Automatically persist extracted memories
   336â†’- [**Memory Management Tools**](../reference/tools.md#langmem.create_manage_memory_tool): Give agents direct access to memory operations
   337â†’
   338â†’Use these if you're using LangGraph Platform or LangGraph OSS, since it's an easy way to add memory capabilities to your agents.
   339â†’
   340â†’
   341â†’## Storage System {#storage-system}
   342â†’
   343â†’??? note "Storage is optional"
   344â†’    
   345â†’    Remember that LangMem's core functionality is built around that don't require any specific storage layer. The storage features described here are part of LangMem's higher-level integration with LangGraph, useful when you want built-in persistence.
   346â†’
   347â†’
   348â†’When using LangMem's stateful operators or platform services, the storage system is built on LangGraph's storage primitives, providing a flexible and powerful way to organize and access memories. The storage system is designed around two concepts:
   349â†’
   350â†’### Memory Namespaces {#memory-namespaces}
   351â†’
   352â†’Memories are organized into namespaces that allow for natural segmentation of data:
   353â†’
   354â†’- **Multi-Level Namespaces**: Group memories by organization, user, application, or any other hierarchical structure
   355â†’- **Contextual Keys**: Identify memories uniquely within their namespace
   356â†’- **Structured Content**: Store rich, structured data with metadata for better organization
   357â†’
   358â†’??? example "Organizing memories hierarchically"
   359â†’
   360â†’    ```python
   361â†’    # Organize memories by organization -> configurable user -> context
   362â†’    namespace = ("acme_corp", "{user_id}", "code_assistant")
   363â†’    ```
   364â†’
   365â†’Namespaces can include template variables (such as `"{user_id}"`) to be populated at runtime from `configurable` fields in the `RunnableConfig`.
   366â†’See [how to dynamically configure namespaces](../guides/dynamically_configure_namespaces.md) for an example, or the [NamespaceTemplate](../reference/utils.md#langmem.utils.NamespaceTemplate) reference docs for more details.
   367â†’
   368â†’### Flexible Retrieval
   369â†’
   370â†’If you use one of the managed APIs, LangMem will integrate directly with LangGraph's [BaseStore](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) interface for memory storage and retrieval. The storage system supports multiple ways to retrieve memories:
   371â†’
   372â†’- [**Direct Access**](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get): Get a specific memory by key
   373â†’- [**Semantic Search**](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search): Find memories by semantic similarity
   374â†’- [**Metadata Filtering**](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search): Filter memories by their attributes
   375â†’
   376â†’For more details on storage capabilities, see the [LangGraph Storage documentation](https://langchain-ai.github.io/langgraph/reference/store/).
   377â†’

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
